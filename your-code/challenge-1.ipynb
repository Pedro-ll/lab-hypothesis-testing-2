{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - T-test\n",
    "\n",
    "In statistics, t-test is used to test if two data samples have a significant difference between their means. There are two types of t-test:\n",
    "\n",
    "* **Student's t-test** (a.k.a. independent or uncorrelated t-test). This type of t-test is to compare the samples of **two independent populations** (e.g. test scores of students in two different classes). `scipy` provides the [`ttest_ind`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_ind.html) method to conduct student's t-test.\n",
    "\n",
    "* **Paired t-test** (a.k.a. dependent or correlated t-test). This type of t-test is to compare the samples of **the same population** (e.g. scores of different tests of students in the same class). `scipy` provides the [`ttest_re`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_rel.html) method to conduct paired t-test.\n",
    "\n",
    "Both types of t-tests return a number which is called the **p-value**. If p-value is below 0.05, we can confidently declare the null-hypothesis is rejected and the difference is significant. If p-value is between 0.05 and 0.1, we may also declare the null-hypothesis is rejected but we are not highly confident. If p-value is above 0.1 we do not reject the null-hypothesis.\n",
    "\n",
    "Read more about the t-test in [this article](http://b.link/test50) and [this Quora](http://b.link/unpaired97). Make sure you understand when to use which type of t-test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset\n",
    "\n",
    "In this challenge we will work on the Pokemon dataset. The goal is to test whether different groups of pokemon (e.g. Legendary vs Normal, Generation 1 vs 2, single-type vs dual-type) have different stats (e.g. HP, Attack, Defense, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "data=pd.read_csv(\"Pokemon.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we want to define a function with which we can test the means of a feature set of two samples. \n",
    "\n",
    "In the next cell you'll see the annotations of the Python function that explains what this function does and its arguments and returned value. This type of annotation is called **docstring** which is a convention used among Python developers. The docstring convention allows developers to write consistent tech documentations for their codes so that others can read. It also allows some websites to automatically parse the docstrings and display user-friendly documentations.\n",
    "\n",
    "Follow the specifications of the docstring and complete the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_features(data,features=['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Total']):\n",
    "    \"\"\"Test means of a feature set of two samples\n",
    "    \n",
    "    Args:\n",
    "        s1 (dataframe): sample 1\n",
    "        s2 (dataframe): sample 2\n",
    "        features (list): an array of features to test\n",
    "    \n",
    "    Returns:\n",
    "        dict: a dictionary of t-test scores for each feature where the feature name is the key and the p-value is the value\n",
    "    \"\"\"\n",
    "\n",
    "    sample1=data[data[\"Legendary\"]]\n",
    "    sample2=data[~data[\"Legendary\"]]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for element in features:\n",
    "\n",
    "        sample_feature_1=sample1[element]\n",
    "        sample_feature_2=sample2[element]\n",
    "\n",
    "        sample_feature_1_mean=sample_feature_1.mean()\n",
    "        sample_feature_2_mean=sample_feature_2.mean()\n",
    "\n",
    "        sample_feature_1_var=sample_feature_1.var(ddof=1)\n",
    "        sample_feature_2_var=sample_feature_2.var(ddof=1)\n",
    "\n",
    "        combined_samp_dist_std=np.sqrt((sample_feature_1_var/len(sample1))+(sample_feature_2_var/len(sample2)))\n",
    "\n",
    "        delta_x=sample_feature_1_mean-sample_feature_2_mean\n",
    "\n",
    "        from scipy import stats as st\n",
    "\n",
    "        df=len(sample1)+len(sample2)-2\n",
    "\n",
    "        t_stat=(delta_x)/(combined_samp_dist_std)\n",
    "\n",
    "        results[element]=st.t.sf(abs(t_stat), df=df)*2\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the `t_test_features` function, conduct t-test for Lengendary vs non-Legendary pokemons.\n",
    "\n",
    "*Hint: your output should look like below:*\n",
    "\n",
    "```\n",
    "{'HP': 1.0026911708035284e-13,\n",
    " 'Attack': 2.520372449236646e-16,\n",
    " 'Defense': 4.8269984949193316e-11,\n",
    " 'Sp. Atk': 1.5514614112239812e-21,\n",
    " 'Sp. Def': 2.2949327864052826e-15,\n",
    " 'Speed': 1.049016311882451e-18,\n",
    " 'Total': 9.357954335957446e-47}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 1.895834084456103e-18,\n",
       " 'Attack': 5.365340994016197e-24,\n",
       " 'Defense': 6.359316889686863e-14,\n",
       " 'Sp. Atk': 3.6722325387208896e-37,\n",
       " 'Sp. Def': 2.534540708359066e-22,\n",
       " 'Speed': 2.5509463508418562e-28,\n",
       " 'Total': 2.026312129890458e-107}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "t_test_features(data)\n",
    "\n",
    "# Values are not exactly equal because I did with the full math expression. But the statistics is the same as the one provided by python function.\n",
    "# Is just a question of computer power because we are dealing with very small numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the test results above, what conclusion can you make? Do Legendary and non-Legendary pokemons have significantly different stats on each feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comment here\n",
    "\n",
    "\"\"\" Since p_value is extremly small, is very very unlikelly that the difference between the two features (Legendary and Non-Legendary) is zero \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, conduct t-test for Generation 1 and Generation 2 pokemons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_Generation(data,features=['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Total']):\n",
    "    \"\"\"Test means of a feature set of two samples\n",
    "    \n",
    "    Args:\n",
    "        s1 (dataframe): sample 1\n",
    "        s2 (dataframe): sample 2\n",
    "        features (list): an array of features to test\n",
    "    \n",
    "    Returns:\n",
    "        dict: a dictionary of t-test scores for each feature where the feature name is the key and the p-value is the value\n",
    "    \"\"\"\n",
    "\n",
    "    sample1=data[data[\"Generation\"]==1]\n",
    "    sample2=data[data[\"Generation\"]==2]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for element in features:\n",
    "\n",
    "        sample_feature_1=sample1[element]\n",
    "        sample_feature_2=sample2[element]\n",
    "\n",
    "        sample_feature_1_mean=sample_feature_1.mean()\n",
    "        sample_feature_2_mean=sample_feature_2.mean()\n",
    "\n",
    "        sample_feature_1_var=sample_feature_1.var(ddof=1)\n",
    "        sample_feature_2_var=sample_feature_2.var(ddof=1)\n",
    "\n",
    "        combined_samp_dist_std=np.sqrt((sample_feature_1_var/len(sample1))+(sample_feature_2_var/len(sample2)))\n",
    "\n",
    "        delta_x=sample_feature_1_mean-sample_feature_2_mean\n",
    "\n",
    "        from scipy import stats as st\n",
    "\n",
    "        df=len(sample1)+len(sample2)-2\n",
    "\n",
    "        t_stat=(delta_x)/(combined_samp_dist_std)\n",
    "\n",
    "        results[element]=st.t.sf(abs(t_stat), df=df)*2\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HP': 0.14518640454367895, 'Attack': 0.24694946690526867, 'Defense': 0.5675156015962366, 'Sp. Atk': 0.12325488503556717, 'Sp. Def': 0.18782815497313365, 'Speed': 0.002361857085507199, 'Total': 0.5630224789577705}\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "results=t_test_Generation(data)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " With a significance level of 5% (alpha = 0.05) only the speed can be considered statistical different between generation 1 and generation 2.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\" With a significance level of 5% (alpha = 0.05) only the speed can be considered statistical different between generation 1 and generation 2.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare pokemons who have single type vs those having two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_types(data,features=['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Total']):\n",
    "    \"\"\"Test means of a feature set of two samples\n",
    "    \n",
    "    Args:\n",
    "        s1 (dataframe): sample 1\n",
    "        s2 (dataframe): sample 2\n",
    "        features (list): an array of features to test\n",
    "    \n",
    "    Returns:\n",
    "        dict: a dictionary of t-test scores for each feature where the feature name is the key and the p-value is the value\n",
    "    \"\"\"\n",
    "\n",
    "    sample1=data[(~data[\"Type 1\"].isna())&(data[\"Type 2\"].isna())]\n",
    "    sample2=data[(~data[\"Type 1\"].isna())&(~data[\"Type 2\"].isna())]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for element in features:\n",
    "\n",
    "        sample_feature_1=sample1[element]\n",
    "        sample_feature_2=sample2[element]\n",
    "\n",
    "        sample_feature_1_mean=sample_feature_1.mean()\n",
    "        sample_feature_2_mean=sample_feature_2.mean()\n",
    "\n",
    "        sample_feature_1_var=sample_feature_1.var(ddof=1)\n",
    "        sample_feature_2_var=sample_feature_2.var(ddof=1)\n",
    "\n",
    "        combined_samp_dist_std=np.sqrt((sample_feature_1_var/len(sample1))+(sample_feature_2_var/len(sample2)))\n",
    "\n",
    "        delta_x=sample_feature_1_mean-sample_feature_2_mean\n",
    "\n",
    "        from scipy import stats as st\n",
    "\n",
    "        df=len(sample1)+len(sample2)-2\n",
    "\n",
    "        t_stat=(delta_x)/(combined_samp_dist_std)\n",
    "\n",
    "        results[element]=st.t.sf(abs(t_stat), df=df)*2\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HP': 0.1131153086977597, 'Attack': 0.00014931591441792315, 'Defense': 2.793592772837236e-08, 'Sp. Atk': 0.00013875848145585812, 'Sp. Def': 0.00010729068721364702, 'Speed': 0.02421417078375663, 'Total': 1.1156074118434091e-07}\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "print(t_test_types(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " With a significance level of 5% (alpha = 0.05) it is possible to say that attack, defense, sp.atk., sp.defense, speed and total can be considered statistical different.\n"
     ]
    }
   ],
   "source": [
    "# Your comment here\n",
    "\n",
    "print(\"\"\" With a significance level of 5% (alpha = 0.05) it is possible to say that attack, defense, sp.atk., sp.defense, speed and total can be considered statistical different.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we want to compare whether there are significant differences of `Attack` vs `Defense`  and  `Sp. Atk` vs `Sp. Def` of all pokemons. Please write your code below.\n",
    "\n",
    "*Hint: are you comparing different populations or the same population?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def t_test_attack_defense(data):\n",
    "    \"\"\"Test means of a feature set of two samples\n",
    "    \n",
    "    Args:\n",
    "        s1 (dataframe): sample 1\n",
    "        s2 (dataframe): sample 2\n",
    "        features (list): an array of features to test\n",
    "    \n",
    "    Returns:\n",
    "        dict: a dictionary of t-test scores for each feature where the feature name is the key and the p-value is the value\n",
    "    \"\"\"\n",
    "\n",
    "    sample1=data\n",
    "    sample2=data\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    sample_feature_1=sample1[\"Attack\"]\n",
    "    sample_feature_2=sample2[\"Defense\"]\n",
    "\n",
    "    sample_feature_1_mean=sample_feature_1.mean()\n",
    "    sample_feature_2_mean=sample_feature_2.mean()\n",
    "\n",
    "    sample_feature_1_var=sample_feature_1.var(ddof=1)\n",
    "    sample_feature_2_var=sample_feature_2.var(ddof=1)\n",
    "\n",
    "    combined_samp_dist_std=np.sqrt((sample_feature_1_var/len(sample1))+(sample_feature_2_var/len(sample2)))\n",
    "\n",
    "    delta_x=sample_feature_1_mean-sample_feature_2_mean\n",
    "\n",
    "    from scipy import stats as st\n",
    "\n",
    "    df=len(sample1)+len(sample2)-2\n",
    "\n",
    "    t_stat=(delta_x)/(combined_samp_dist_std)\n",
    "\n",
    "    results[\"Attack vs Defense\"]=st.t.sf(abs(t_stat), df=df)*2\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attack vs Defense': 0.0012123980547321372}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_attack_defense(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " With a significance level of 5% (alpha = 0.05) it is possible to say that attack and defense are statistical different.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\" With a significance level of 5% (alpha = 0.05) it is possible to say that attack and defense are statistical different.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_spattack_spdefense(data):\n",
    "    \"\"\"Test means of a feature set of two samples\n",
    "    \n",
    "    Args:\n",
    "        s1 (dataframe): sample 1\n",
    "        s2 (dataframe): sample 2\n",
    "        features (list): an array of features to test\n",
    "    \n",
    "    Returns:\n",
    "        dict: a dictionary of t-test scores for each feature where the feature name is the key and the p-value is the value\n",
    "    \"\"\"\n",
    "\n",
    "    sample1=data\n",
    "    sample2=data\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    sample_feature_1=sample1[\"Sp. Atk\"]\n",
    "    sample_feature_2=sample2[\"Sp. Def\"]\n",
    "\n",
    "    sample_feature_1_mean=sample_feature_1.mean()\n",
    "    sample_feature_2_mean=sample_feature_2.mean()\n",
    "\n",
    "    sample_feature_1_var=sample_feature_1.var(ddof=1)\n",
    "    sample_feature_2_var=sample_feature_2.var(ddof=1)\n",
    "\n",
    "    combined_samp_dist_std=np.sqrt((sample_feature_1_var/len(sample1))+(sample_feature_2_var/len(sample2)))\n",
    "\n",
    "    delta_x=sample_feature_1_mean-sample_feature_2_mean\n",
    "\n",
    "    from scipy import stats as st\n",
    "\n",
    "    df=len(sample1)+len(sample2)-2\n",
    "\n",
    "    t_stat=(delta_x)/(combined_samp_dist_std)\n",
    "\n",
    "    results[\"Sp. Attack vs Sp. Defense\"]=st.t.sf(abs(t_stat), df=df)*2\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sp. Attack vs Sp. Defense': 0.5458436328840354}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_spattack_spdefense(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " With a significance level of 5% (alpha = 0.05) it is not possible to say that sp attack and sp defense are statistical different.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\" With a significance level of 5% (alpha = 0.05) it is not possible to say that sp attack and sp defense are statistical different.\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
